
\documentclass[a4paper,11pt]{article}
\usepackage[a4paper, margin=8em]{geometry}

% usa i pacchetti per la scrittura in italiano
\usepackage[french,italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\frenchspacing 

% usa i pacchetti per la formattazione matematica
\usepackage{amsmath, amssymb, amsthm, amsfonts}

% usa altri pacchetti
\usepackage{gensymb}
\usepackage{hyperref}
\usepackage{standalone}

% imposta il titolo
\title{Appunti Calcolo Numerico}
\author{Luca Seggiani}
\date{2025}

% disegni
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}

% imposta lo stile
% usa helvetica
\usepackage[scaled]{helvet}
% usa palatino
\usepackage{palatino}
% usa un font monospazio guardabile
\usepackage{lmodern}

\renewcommand{\rmdefault}{ppl}
\renewcommand{\sfdefault}{phv}
\renewcommand{\ttdefault}{lmtt}

% disponi il titolo
\makeatletter
\renewcommand{\maketitle} {
	\begin{center} 
		\begin{minipage}[t]{.8\textwidth}
			\textsf{\huge\bfseries \@title} 
		\end{minipage}%
		\begin{minipage}[t]{.2\textwidth}
			\raggedleft \vspace{-1.65em}
			\textsf{\small \@author} \vfill
			\textsf{\small \@date}
		\end{minipage}
		\par
	\end{center}

	\thispagestyle{empty}
	\pagestyle{fancy}
}
\makeatother

% disponi teoremi
\usepackage{tcolorbox}
\newtcolorbox[auto counter, number within=section]{theorem}[2][]{%
	colback=blue!10, 
	colframe=blue!40!black, 
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries, 
	title=Teorema~\thetcbcounter: #2, 
	#1
}

% disponi definizioni
\newtcolorbox[auto counter, number within=section]{definition}[2][]{%
	colback=red!10,
	colframe=red!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Definizione~\thetcbcounter: #2,
	#1
}

% disponi problemi
\newtcolorbox[auto counter, number within=section]{problem}[2][]{%
	colback=green!10,
	colframe=green!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Problema~\thetcbcounter: #2,
	#1
}

% disponi codice
\usepackage{listings}
\usepackage[table]{xcolor}

\lstdefinestyle{codestyle}{
		backgroundcolor=\color{black!5}, 
		commentstyle=\color{codegreen},
		keywordstyle=\bfseries\color{magenta},
		numberstyle=\sffamily\tiny\color{black!60},
		stringstyle=\color{green!50!black},
		basicstyle=\ttfamily\footnotesize,
		breakatwhitespace=false,         
		breaklines=true,                 
		captionpos=b,                    
		keepspaces=true,                 
		numbers=left,                    
		numbersep=5pt,                  
		showspaces=false,                
		showstringspaces=false,
		showtabs=false,                  
		tabsize=2
}

\lstdefinestyle{shellstyle}{
		backgroundcolor=\color{black!5}, 
		basicstyle=\ttfamily\footnotesize\color{black}, 
		commentstyle=\color{black}, 
		keywordstyle=\color{black},
		numberstyle=\color{black!5},
		stringstyle=\color{black}, 
		showspaces=false,
		showstringspaces=false, 
		showtabs=false, 
		tabsize=2, 
		numbers=none, 
		breaklines=true
}

\lstdefinelanguage{javascript}{
	keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
	keywordstyle=\color{blue}\bfseries,
	ndkeywords={class, export, boolean, throw, implements, import, this},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{//},
	morecomment=[s]{/*}{*/},
	commentstyle=\color{purple}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	morestring=[b]',
	morestring=[b]"
}

% disponi sezioni
\usepackage{titlesec}

\titleformat{\section}
	{\sffamily\Large\bfseries} 
	{\thesection}{1em}{} 
\titleformat{\subsection}
	{\sffamily\large\bfseries}   
	{\thesubsection}{1em}{} 
\titleformat{\subsubsection}
	{\sffamily\normalsize\bfseries} 
	{\thesubsubsection}{1em}{}

% disponi alberi
\usepackage{forest}

\forestset{
	rectstyle/.style={
		for tree={rectangle,draw,font=\large\sffamily}
	},
	roundstyle/.style={
		for tree={circle,draw,font=\large}
	}
}

% disponi algoritmi
\usepackage{algorithm}
\usepackage{algorithmic}
\makeatletter
\renewcommand{\ALG@name}{Algoritmo}
\makeatother

% disponi numeri di pagina
\usepackage{fancyhdr}
\fancyhf{} 
\fancyfoot[L]{\sffamily{\thepage}}

\makeatletter
\fancyhead[L]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@title \ \@date}}} 
\fancyhead[R]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@author}}}
\makeatother

\begin{document}

% sezione (data)
\section{Lezione del 03-03-25}

% stili pagina
\thispagestyle{empty}
\pagestyle{fancy}

% testo
\subsection{Riassunto sulla stima dell'errore}
Riassumiamo quindi le regole viste per la stima dell'errore su funzioni razionali.
Avevamo dato la definizione di errore \textbf{assoluto} $\sigma_f$ e errore \textbf{relativo} $\epsilon_f$, entrambi composti da due fattori denominati errore \textbf{algoritmico} e errore \textbf{inerente}, con pedici rispettivamente $a$ e $d$.

\begin{itemize}
	\item 
Riguardo all'errore \textbf{inerente assoluto} avevamo preso su un dominio $D$ la stime:

$$
|\sigma_d| \leq \sum_{j = 1}^m A_j \cdot |\sigma_j|
$$
con $|\sigma^j|$ \textbf{errore di arrotondamento} e $A_j$ \textbf{coefficiente di amplificazione}:
$$
A_j = \max_{P \in D} \left( \frac{\partial f}{\partial x_j}(P) \right)
$$

Per l'errore di arrotondamento avevamo visto potevamo prendere:
$$
|\sigma_j| \leq U \cdot |x_j|
$$
con $U$ precisione macchina.

	\item
Riguardo all'\textbf{errore inerente relativo} avevamo invece preso:
$$
|\epsilon_d|\leq \sum_{j = 1}^m \overline{A}_j \cdot |\epsilon_j|
$$
con
$|\epsilon_j|$ \textbf{errore di arrotondamento relativo} e $\overline{\sigma_j}$ \textbf{coefficiente di amplificazione relativo}:
$$
\overline{A_j} = \max_{P \in D} \left( \frac{x_j \cdot \frac{\partial f}{\partial x_j} (P) }{f(P)} \right)
$$

Per l'errore di arrotondamento relativo potevamo quindi prendere:
$$
|\epsilon_j| \leq U
$$
\end{itemize}

\par\smallskip 

Vediamo come ultimo esempio il calcolo dell'errore relativo $|\epsilon_f|$ per la funzione:
$$
f(x_1, x_2) = (x_1 + 1) x_1 + x_2
$$

\begin{itemize}
	\item Iniziamo con il calcolo dell'errore inerente, senza fare assunzioni su $\epsilon_{x_i}$:
		$$
		|\epsilon_d| \leq \frac{ x_1 \cdot \frac{\partial f}{\partial x_1}(x_1, x_2)}{f(x_1, x_2)} \epsilon_{x_1} + \frac{ x_2 \cdot \frac{\partial f}{\partial x_2}(x_1, x_2)}{f(x_1, x_2)} \epsilon_{x_2}
		= \frac{x_1(2x_1 + 1)}{(x_1 + 1)x_1 + x_2} \epsilon_{x_1} + \frac{x_2}{(x_1 + 1)x_1 + x_2} \epsilon_{x_1}
		$$
	\item Calcoliamo poi l'errore algoritmico dell'algoritmo:
		\begin{center}
			\begin{forest}
				[
					{$r_3 = r_2 + x_2$}
					[
						{$r_2 = r_1 x_1$}
						[
							{$r_1 = x_1 + 1$}	
							[
								{$x_1$}
							]
							[
								{$1$}
							]
						]
						[
							{$x_1$}
						]
					]	
					[
						{$x_2$}
					]	
				]	
			\end{forest}
		\end{center}
		da cui:
		$$
		|\epsilon_a| \leq \epsilon_3 + \frac{(x_1 + 1) x_1}{(x_1 + 1)x_1 + x_2} \epsilon_{r_2} + \frac{x_2}{(x_1 + 1)x_1 + x_2} \epsilon_{x_2}
		= \epsilon_3 + \frac{(x_1 + 1) x_1}{(x_1 + 1)x_1 + x_2} (\epsilon_2 + \epsilon_{r_1} + \epsilon_{x_1})
		$$
		$$
		= \epsilon_3 + \frac{(x_1 + 1) x_1}{(x_1 + 1)x_1 + x_2} (\epsilon_2 + \epsilon_1 + \frac{x_1}{x_1 + 1} \epsilon_{x_1} + \frac{1}{x_1 + 1} \cdot 0) = \epsilon_3 + \frac{(x_1 + 1) x_1}{(x_1 + 1) x_1 + x_2}	(\epsilon_2 + \epsilon_1)
		$$
\end{itemize}

Abbiamo quindi l'errore complessivo:
$$
|\epsilon_f| \leq |\epsilon_a| + |\epsilon_d| = \epsilon_3 + \frac{(x_1 + 1) x_1}{(x_1 + 1) x_1 + x_2}	(\epsilon_2 + \epsilon_1) + \frac{x_1(2x_1 + 1)}{(x_1 + 1)x_1 + x_2} \epsilon_{x_1} + \frac{x_2}{(x_1 + 1)x_1 + x_2} \epsilon_{x_1}
$$

\subsection{Errori di funzioni non razionali}
Abbiamo finora trascurato il caso di funzioni non razionali.
Prendiamo ad esempio di voler calcolare l'errore su funzioni come $e^{\cos(x + y)}$.
In questo caso sarà necessario usare un approssimazione razionale di $f$ che chiamiamo $\overline{f}$, che poi porteremo a $\overline{f}_a$ che usa operazioni macchina detta \textbf{algoritmo}.
In questo caso l'errore sarà dato dall'\textit{errore inerente}, dall'\textit{errore algortimico} e dall'\textbf{errore analitico} $\sigma_{an}$ della funzione, cioè potremo dire:

$$
\overline{f}_a (P_1) - f(P_0) = \overline{f}_a (P_1) - \overline{f} (P_1) + \overline{f} (P_1) - f(P_1) + f(P_1) - f(P_0) = \sigma_a + \sigma_{an} + \sigma_d
$$
	L'errore inerente sarà calcolato sulla $f$ originale, mentre l'errore analitico sarà calcolato con la nuova $\overline{f}$, e in particolare dipenderà dall'approssimazione razionale che usiamo.

Vediamo per adesso approssimazioni polinomiali attraverso la \textbf{formula di Taylor}. Nel caso scalare si ha:

\begin{theorem}{Formula di Taylor}
	Data $f : \mathbb{R} \rightarrow \mathbb{R}$, $f \in C^1$, allora dato $x_0 \in \mathbb{R}$ si ha:
	$$
	f(x) = \sum_{n = 0}^k \frac{ f^{(n)}(x_0) }{ n! } \cdot (x - x_0)^n + \frac{ f^{(k + 1)} ( \eta ) }{(k + 1)!} (x - x_0)^{k + 1} 
	$$
	Dove:
	$$
		\epsilon_l = \frac{ f^{(k + 1)} ( \eta ) }{(k + 1)!} (x - x_0)^{k + 1}
	$$
	rappresenta l'\textbf{errore di Lagrange} al $k$-esimo grado, con $\eta \in [x_0, x]$ il punto di massimo della $k + 1$-esima derivata di $f$.
\end{theorem}

In questo caso:
$$
\overline{f}(x) = \sum_{n = 0}^k \frac{ f^{(n)}(x_0) }{ n! } \cdot (x - x_0)^n
$$
cioè la serie di Taylor troncata al $k$-esimo grado sarà una buona approssimazione per $f$, e l'errore analitico sarà dato da:
$$
\sigma_{an} = R(x) = f(x) - T(x, k, x_0) 
$$
		con $R(x)$ il resto fra lo sviluppo di Taylor troncato $T(x, k)$ e la funzione stessa $f(x)$.
In questo caso fissato $k$ si potrà dare una stima di errore direttamente dall'errore di Lagrange, cioè:
$$
R(x) = f(x) - T(x, k, x_0) = \frac{ f^{(k + 1)} ( \eta ) }{(k + 1)!} (x - x_0)^{k + 1}
$$
e più in particolare, sfruttando il limite superiore dato da:
$$
R(x) \leq \epsilon_l = \frac{ \max_{[x_0, x]} \left( f^{(k + 1)} \right) }{(k + 1)!} (x - x_0)^{k + 1} = \frac{M}{(k + 1)!}(x - x_0)^{k + 1}
$$

\subsubsection{Approssimazione dell'esponenziale}
Prendiamo di volere calcolare l'errore dato dall'approssimazione dell'esponenziale al $k$-esimo grado su un intervallo comprensivo di $x_0 = 0$, che chiamiamo $D = [-l, u]$.
Avremo quindi l'approssimazione:
$$
e^x = T(x, k, 0) = \sum_{n = 0}^k \frac{(x - x_0)^n}{n!}
$$
e la funzione resto:
$$
R(
x) = e^x - T(x, k, 0) = \frac{f^{(k + 1)}(\eta)}{(k + 1)!}x^{k + 1}
$$

prendiamo quindi la stima superiore di $f^{(k + 1)}(\eta)$ su $\eta \in D$ (il caso peggiore sarà quello in cui valutiamo $x$ sull'estremo superiore $u$):
$$
f^{(k + 1)} (\eta) \leq \max_{\eta \in [0, u]} f^{( k + 1)}(\eta) = e^u
$$
da cui:
$$
R(x) \leq \frac{e^u x^{k + 1}}{(k + 1)!}
$$
Stimiamo allora l'errore analitico relativo come:
$$
|\epsilon_{an}| = \frac{R(x)}{f(x)} \leq \frac{ \max_{[-l, u]} \Big| \frac{e^ux^{k + 1}}{(k + 1)!} \Big| }{ \min_{[-l, u]} e^x } = \frac{e^{u-l}u^{k+1}}{(k+1)!}
$$

\subsubsection{Note sull'implementazione dell'esponenziale}
Vediamo alcuni dettagli sull'implementazione pratica di un'approssimazione dell'esponenziale nel linguaggio MATLAB/Octave.
Il primo modo che potrebbe venire in mente prevede di mantenere un numeratore e un denominatore:
\begin{lstlisting}[language=matlab, style=codestyle]	
function val = myexp1(x, n)
		num = 1;
		den = 1;
		
		val = 1;

    for i = 1:n
    	num = num * x;
			den = den * i;

			val = val + num / den;
		end
end
\end{lstlisting}

Notiamo però che questo approccio presenta notevole instabilità numerica con grandi valori di $k$, ad esempio si veda:
\begin{lstlisting}[language=matlab, style=codestyle]	
>> myexp(20, 500)
ans =
   NaN
\end{lstlisting}

\lstset{language = matlab, style = codestyle}

Questo deriva dal fatto che per grandi valori di $k$ si ottiene eventualmente \lstinline|num = Inf| e \lstinline|den = Inf|, da cui il \lstinline|NaN|.
Un'approccio migliore si ha quindi mantenendo direttamente il termine e accumulandolo:
\begin{lstlisting}[language=matlab, style=codestyle]	
function acc = myexp2(x, n)
    term = 1;
    acc = 1;

    for i = 1:n
        term = term * x / i;
        acc = acc + term;
    end
end
\end{lstlisting}

Notiamo però che in questo caso si hanno problemi di cancellazione per argomenti negativi, ad esempio si veda:
\begin{lstlisting}[language=matlab, style=codestyle]	
>> myexp(-30, 500)
ans =
  -3.0668e-05
\end{lstlisting}
In questo caso si ha più accuratezza imponendo argomenti positivi, ad esempio sfruttando:
$$
e^{-x} = \frac{1}{e^x}
$$
Si veda ad esempio:
\begin{lstlisting}[language=matlab, style=codestyle]	
>> 1/myexp(30, 500)
ans =
   9.3576e-14
\end{lstlisting}

Modifichiamo quindi la funzione per rilevare automaticamente esponenti negativi e adottare la forma corretta:

\begin{lstlisting}[language=matlab, style=codestyle]	
function acc = myexp3(x, n)
    neg = false;
    if x < 0
        neg = true;
        x = -x;
    end

    term = 1;
    acc = 1;

    for i = 1:n
        term = term * x / i;
        acc = acc + term;
    end

    if neg
        acc = 1 / acc;
    end
end
\end{lstlisting}

Provando questa funzione su un range di interi da $-30$ a $30$, con la serie di Taylor troncata a $500$, dà un errore massimo rispetto al valore reale di circa $10^{-16} \sim 10^{-17}$.

\par\bigskip

Veniamo quindi a fare alcuni richiami di algebra lineare.
Nella maggior parte dei casi che ci interessano vorremo trattare non di scalari, ma di quantità vettoriali, ad esempio $x \in \mathbb{C}^n$, con $n > 1$.

\subsection{Matrici complesse}
Ci saranno utili le matrici perchè rappresentano direttamente tutte le \textbf{funzioni lineari}. 
Ad esempio, posta $f: \mathbb{C}^n \rightarrow \mathbb{C}^m$ tale che:
\begin{itemize}
	\item $ f(x + y) = f(x) + f(y) $ (addittività);
	\item $f(\lambda x) = \lambda f(x)$ (omogeneità)
\end{itemize}
detta \textit{funzione lineare} allora $\exists ! A \in \mathbb{C}^{m \times n}$ tale che $f(x) = A x$,  $\forall x \in \mathbb{C}^n$.

Nel corso useremo sia matrici in $\mathbb{R}$ che matrici in $\mathbb{C}$, dove l'appartenenza a ciascuno di questi campi dipende dalla appartenenza di essi delle \textbf{entrate} $A_{ij}$ della matrice.
In ogni caso, una matrice reale non sarà che un caso particolare delle matrici complesse.

Si danno poi per scontate le definizioni di matrici:
\begin{itemize}
	\item \textit{Quadrate} ($n = m$):
	\item \textit{Rettangolari} ($n \neq m$);
	\item \textit{Diagonali} (elementi nulli fuori dalla diagonale);
	\item \textit{Triangolari superiori/inferiori} (elementi nulli sotto/sopra la diagonale) 
\end{itemize}

\subsubsection{Trasposta coniugata}
Definiamo infine la \textbf{trasposta coniugata} di una certa matrice, generalizzata al campo complesso dalla \textbf{matrice hermitiana}:
\begin{definition}{Trasposta coniugata}
	Data una matrice $A \in \mathbb{C}^{n \times m}$, la trasposta coniugata $A^T$ sarà:
	$$
		(A^T)_{ij} = A_{ji}
	$$
	e la matrice hermitiana $A^H$ sarà: 
	$$
		(A^H)_{ij} = \overline{A_{ji}}
	$$
\end{definition}

\subsection{Algebra vettoriale}
Diamo alcune nozioni riguardo alle operazioni fra vettori.

\subsubsection{Prodotto scalare}
Diamo la definizione di prodotto scalare, generalizzato al campo complesso dal \textbf{prodotto hermitiano} (entrambi \textit{prodotti interni}):
\begin{definition}{Prodotto interno}
	Definiamo il prodotto interno fra due vettori $x, y \in \mathbb{C}^n$ come:
	$$
	<x, y> = \sum_{j = 1}^n x_j \overline{y_j}
	$$
\end{definition}
dove $\overline{y_j}$ rappresenta il \textbf{coniugato} di $y_j$, che chiaramente in $\mathbb{R}$ si riduce a $y_j$ stesso e quindi:
	$$
	<x, y> = \sum_{j = 1}^n x_j y_j, \quad x, y \in \mathbb{R}^n
	$$ 


\subsubsection{Indipendenza lineare}
Diamo la definizione di indipendenza linare:
\begin{definition}{}
	Un insieme di vettori $\{x_1, ..., x_s\}$ si dice linearemente indipendente se:
	$$
		x_1 + ... + x_s = 0 \leftrightarrow x_1, ..., x_s = 0
	$$
\end{definition}

Possiamo sfruttare l'indipendenza lineare per definire \textbf{basi}:
\begin{definition}{Base}
	Se $s = n$ l'insieme $\{ x_1, ...,x_s \}$ si dice \textbf{base} di $\mathbb{C}^n$.
\end{definition}

Questo significa che $\forall y \in \mathbb{C}^m$, \ $\exists ! \{c1, ..., c_s\}$ tali che $y = \sum_{j=1}^n c_j x_j$, cioè combinazioni lineari dei vettori di base individuano qualsiasi vettore nello spazio $\mathbb{C}^n$.


\subsection{Operazioni fra matrici}
Date due matrici $A$ e $B$ con lo stesso numero di righe e colonne si possono definire le operazioni:
\begin{itemize}
	\item \textbf{Somma:} $A, B, C \in \mathbb{C}^{m \times n}$, $A + B = C$, $c_{ij} = a_{ij} + b_{ij}$;
	\item \textbf{Prodotto:} $A \in \mathbb{C}^{m \times n}, B \in \mathbb{C}^{n \times p}, C \in \mathbb{C}^{m \times p}$, $A \cdot B = C$, $c_{ij} = \sum_{h = 1}^n a_{ih} b_{hj}$ sia in reali che in complessi. 
\end{itemize}

\subsubsection{Considerazioni computazionali sulle operazioni matriciali}
Dal punto di vista computazionale, è immediato che il prodotto scalare ha complessità $O(n)$, la somma matriciale ha complessità $O(m \cdot n)$.

Per la moltiplicazione matriciale, poste:
$$
A \in \mathbb{C}^{m \times n}, \quad B \in \mathbb{C}^{n \times p}
\implies A \cdot B = C \in \mathbb{C}^{m \times p}
$$
si ha che la complessità è $O(m \cdot n \cdot p)$.

L'ultimo risultato dipende dal fatto che la moltiplicazione richiede di effetuarre effettivamente $m \cdot p$ prodotti scalari, e $n$ è la lunghezza di uno di questi prodotti scalari, cio il numero di colonne di $A$ o di righe di $B$ (che sappiamo essere uguali perché la moltplicazione sia possibile in primo luogo).

Questo significa che per matrici quadrate si ha generalmente complessità $O(n^3)$ (anche se esistono algoritmi che si avvicinano al bound inferiore di $O(n^2)$).

\end{document}
