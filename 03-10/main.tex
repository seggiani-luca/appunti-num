
\documentclass[a4paper,11pt]{article}
\usepackage[a4paper, margin=8em]{geometry}

% usa i pacchetti per la scrittura in italiano
\usepackage[french,italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\frenchspacing 

% usa i pacchetti per la formattazione matematica
\usepackage{amsmath, amssymb, amsthm, amsfonts}

% usa altri pacchetti
\usepackage{gensymb}
\usepackage{hyperref}
\usepackage{standalone}

% imposta il titolo
\title{Appunti Calcolo Numerico}
\author{Luca Seggiani}
\date{2025}

% disegni
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}

% imposta lo stile
% usa helvetica
\usepackage[scaled]{helvet}
% usa palatino
\usepackage{palatino}
% usa un font monospazio guardabile
\usepackage{lmodern}

\renewcommand{\rmdefault}{ppl}
\renewcommand{\sfdefault}{phv}
\renewcommand{\ttdefault}{lmtt}

% disponi il titolo
\makeatletter
\renewcommand{\maketitle} {
	\begin{center} 
		\begin{minipage}[t]{.8\textwidth}
			\textsf{\huge\bfseries \@title} 
		\end{minipage}%
		\begin{minipage}[t]{.2\textwidth}
			\raggedleft \vspace{-1.65em}
			\textsf{\small \@author} \vfill
			\textsf{\small \@date}
		\end{minipage}
		\par
	\end{center}

	\thispagestyle{empty}
	\pagestyle{fancy}
}
\makeatother

% disponi teoremi
\usepackage{tcolorbox}
\newtcolorbox[auto counter, number within=section]{theorem}[2][]{%
	colback=blue!10, 
	colframe=blue!40!black, 
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries, 
	title=Teorema~\thetcbcounter: #2, 
	#1
}

% disponi definizioni
\newtcolorbox[auto counter, number within=section]{definition}[2][]{%
	colback=red!10,
	colframe=red!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Definizione~\thetcbcounter: #2,
	#1
}

% disponi problemi
\newtcolorbox[auto counter, number within=section]{problem}[2][]{%
	colback=green!10,
	colframe=green!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Problema~\thetcbcounter: #2,
	#1
}

% disponi codice
\usepackage{listings}
\usepackage[table]{xcolor}

\lstdefinestyle{codestyle}{
		backgroundcolor=\color{black!5}, 
		commentstyle=\color{codegreen},
		keywordstyle=\bfseries\color{magenta},
		numberstyle=\sffamily\tiny\color{black!60},
		stringstyle=\color{green!50!black},
		basicstyle=\ttfamily\footnotesize,
		breakatwhitespace=false,         
		breaklines=true,                 
		captionpos=b,                    
		keepspaces=true,                 
		numbers=left,                    
		numbersep=5pt,                  
		showspaces=false,                
		showstringspaces=false,
		showtabs=false,                  
		tabsize=2
}

\lstdefinestyle{shellstyle}{
		backgroundcolor=\color{black!5}, 
		basicstyle=\ttfamily\footnotesize\color{black}, 
		commentstyle=\color{black}, 
		keywordstyle=\color{black},
		numberstyle=\color{black!5},
		stringstyle=\color{black}, 
		showspaces=false,
		showstringspaces=false, 
		showtabs=false, 
		tabsize=2, 
		numbers=none, 
		breaklines=true
}

\lstdefinelanguage{javascript}{
	keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
	keywordstyle=\color{blue}\bfseries,
	ndkeywords={class, export, boolean, throw, implements, import, this},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{//},
	morecomment=[s]{/*}{*/},
	commentstyle=\color{purple}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	morestring=[b]',
	morestring=[b]"
}

% disponi sezioni
\usepackage{titlesec}

\titleformat{\section}
	{\sffamily\Large\bfseries} 
	{\thesection}{1em}{} 
\titleformat{\subsection}
	{\sffamily\large\bfseries}   
	{\thesubsection}{1em}{} 
\titleformat{\subsubsection}
	{\sffamily\normalsize\bfseries} 
	{\thesubsubsection}{1em}{}

% disponi alberi
\usepackage{forest}

\forestset{
	rectstyle/.style={
		for tree={rectangle,draw,font=\large\sffamily}
	},
	roundstyle/.style={
		for tree={circle,draw,font=\large}
	}
}

% disponi algoritmi
\usepackage{algorithm}
\usepackage{algorithmic}
\makeatletter
\renewcommand{\ALG@name}{Algoritmo}
\makeatother

% disponi numeri di pagina
\usepackage{fancyhdr}
\fancyhf{} 
\fancyfoot[L]{\sffamily{\thepage}}

\makeatletter
\fancyhead[L]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@title \ \@date}}} 
\fancyhead[R]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@author}}}
\makeatother

\begin{document}

% sezione (data)
\section{Lezione del 10-03-25}

% stili pagina
\thispagestyle{empty}
\pagestyle{fancy}

% testo
\subsection{Autovalori e autovettori}
Continuiamo a parlare di matrici quadrate, e introduciamo gli \textbf{autovalori} e \textbf{autovettori}:
\begin{definition}{Autovalori e autovettori destri}
	Data $A \in \mathbb{C}^{n\times n}$, $\lambda \in \mathbb{C}$ si dice autovalore se esiste un vettore $v$ in $\mathbb{C}^{n}$, con $v \neq 0$, tale che:
	$$
		Av = \lambda v
	$$
\end{definition}

L'equazione $Av = \lambda v$ non rappresenta un sistema lineare, in quanto sia $v$ che $\lambda$ sono variabili (e fra l'altro moltiplicate fra loro).

In particolare, $v$ si dice \textbf{autovettore destro} per $A$ rispetto a $\lambda$.
Similmente, si può definire $w$ \textbf{autovettore sinistro}:
\begin{definition}{Autovalori e autovettori sinistri}
	Data $A \in \mathbb{C}^{n\times n}$, $\lambda \in \mathbb{C}$ si dice autovalore se esiste un vettore $w$ in $\mathbb{C}^{n}$, con $w \neq 0$, tale che:
	$$
		w^H A = w^H \lambda
	$$
\end{definition}

Solitamente ci basta trovare gli autovettori destri in quanto:
$$
(w^H A)^H = A^H w 
$$
$$
(\lambda w^H)^H = \overline{\lambda} w
$$
cioè $w$ è un autovettore destro per $\lambda$ se e solo se $w$ è autovettore destro per $A^H$ rispetto all'autovalore $\overline{\lambda}$.
In questo caso, se la matrice è \textit{simmetrica} o \textit{hermitiana}, gli autovalori destri e sinistri coincidono.

\subsubsection{Caratterizzazione degli autovalori}
Potremmo interrogarci sull'esistenza di questi oggetti.
Poniamo allora:
$$
Av = \lambda v \implies Av - \lambda v = 0 \implies (A - \lambda I) v = 0
$$
Chiaramente il sistema è risolto per $v = 0$, ma abbiamo escluso a priori tale possibilità.
Abbiamo allora un sistema $A - \lambda I$, che ha almeno una soluzione per Rouché-Capelli, che è $0$ se $\det(A - \lambda I) \neq 0$, e un valore $\neq 0$ altrimenti.
Vogliamo quindi impostare:
$$
p(\lambda) = \det(A - \lambda I) = 0
$$
detta \textbf{equazione caratteristica} (del \textit{polinomio caratteristico} posto nullo).
Gli autovalori non saranno altro che le soluzioni dell'equazione caratteristica.

L'esistenza di tali soluzioni è data dal fatto che $\mathrm{deg}\left(p(\lambda)\right) = n$, e quindi dal teorema fondamentale dell'algebra esistono $c_0, c_1, ..., c_n$ tali che:
$$
p(\lambda) = c_0 + c_1 \lambda + ... + c_n \lambda^n = c_n (\lambda - \lambda_1) ... (\lambda - \lambda_n) = (-1)^n (\lambda - \lambda_1) ... (\lambda - \lambda_n)
$$
e dal punto di vista dei minori:
$$
= (-1)^n \lambda^n + (-1)^{n - 1} \sigma_1 \lambda^{n - 1} + ... + (-1)^1 \sigma_{n - 1} \lambda + (-1)^0 \sigma_{n}
$$
$$
= (-1)^n \lambda^n + (-1)^{n - 1} \sigma_1 \lambda^{n - 1} + ... - \sigma_{n - 1} \lambda + \sigma_{n}
$$
dove $\sigma_j$ è la somma dei determinanti delle sottomatrici di $A$ di ordine $j$.
Alcuni di questi $\sigma_j$ sono semplici da calcolare:
$$
\sigma_1 = \sum_{i = 1}^n a_{ii} = \mathrm{tr}(A) \quad \text{(traccia)}
$$
$$
\sigma_n = \prod_{j=1}^m \lambda_j = \det(A)
$$
vediamo quest'ultima relazione: si ha che il determinante di una matrice è uguale al prodotto dei suoi autovalori, ergo:
$$
\det(A) = 0 \, \Leftrightarrow \, \exists \lambda_j = 0
$$

\par\smallskip

Riepilogando una matrice $\in \mathbb{C}^{n \times n}$ ha sempre esattamante $n$ autovalori, contati con la loro molteplicità.
In particolare:
\begin{definition}{Molteplicità algebrica}
	Un autovalore $\overline{\lambda}$ ha molteplicità algebrica $k$ ($\alpha(\overline{\lambda})) = k$) se $k$ è la sua molteplicità $\mu$ come radice del polinomio caratteristico.
\end{definition}

Chiaramente:
$$
\sum_{\overline{\lambda}} \alpha(\overline{\lambda}) = n
$$

\subsubsection{Caratterizzazione degli autovettori}
Potremmo chiederci quanti sono gli autovettori.
Abbiamo allora che:
$$
A v = \lambda v
$$
e preso $\theta \in \mathbb{C}$ allora:
$$
A(\theta v) = \theta A v
 = \theta \lambda v = \lambda (\theta v)
 $$
cioè anche $\theta v$ è autovalettore per $\lambda^* = \theta \lambda$.
Questo ci dice che gli autovettori non sono mai unici.
Inoltre, possiamo dire che dati $A v_1 = \lambda v_1$ e $A v_2 = \lambda v_2$:
$$
A(v1 + v_2) = A v_1 + A v_2 = \lambda v_1 + \lambda v_2 = \lambda (v_1 + v_2)
$$
cioè sono soddisfatte le proprietà di omogeneità e additività, e quindi l'insieme degli autovettori relativi a un certo autovalore $\lambda$ forma uno spazio vettoriale (detto \textbf{autospazio} rispetto a $\lambda$).

Questo ci permette di definire un'altra molteplicità:
\begin{definition}{Molteplicità geometrica}
	Dato $\lambda \in \mathbb{C}$ autovalore di $A \in \mathbb{C}^{n \times n}$ si dice molteplicità geometrica $k$ ($\gamma(\lambda) = k$) la dimensione dell'autospazio associato a $\lambda$, ovvero:
	$$
		\gamma(\lambda) = \mathrm{dim}\left( \mathrm{ker}(A - \lambda I) \right)
	$$
\end{definition}

Per Rouché-Capelli, si ha che:
$$
\gamma(\lambda) = n - \mathrm{rank}(A - \lambda I)
$$

Valgono poi le relazioni fra molteplicità algebrica e molteplicità geometrica:
$$
1 \leq \gamma(\lambda) \leq \alpha(\lambda) \leq n
$$

Inoltre se si hanno $\lambda_i \neq \lambda_j$ autovalori distinti ($\forall i \neq j$, $i, j \in \{1, ..., n\}$), allora necessariamente:
$$
\gamma(\lambda_i) = \alpha(\lambda_i) = 1, \quad \forall i = 1 , ..., n
$$
cioè se tutti gli autovalori di $A$ sono distinti, le loro molteplicità, sia $\alpha$ che $\gamma$, devono essere uguali a 1.

\subsubsection{Matrici simili}
Possiamo quindi definire la \textbf{similarità} fra matrici:
\begin{definition}{Matrici simili}
	Date $A, B \in \mathbb{C}^{n \times n}$, si dicono simili ($B \sim A$) se esiste $S \in \mathbb{C}^{n \times n}$ invertibile tale che:
	$$
		B = S^{-1} A S
	$$
\end{definition}
in questo caso vale anche l'inverso:
$$
A = S B S^{-1}
$$

Le matrici fra di loro simili hanno diverse proprietà in comune.
Ad esempio, $A \sim B$ hanno gli stessi autovalori con le stesse molteplicità $\alpha$ e $\gamma$.
Inoltre se $v$ è autovettore per $A$ associato a $\lambda$, allora $S^{-1} v$ è autovettore per $B$ associato sempre a $\lambda$.
Questo si dimostra da:
$$
\det(B - \lambda I) = 0 = \det(S^{-1} A S - \lambda I) = \det(S^{-1} A S - \lambda S^{-1}S) = \det(S^{-1} (A - \lambda I) S)
$$
e da Binet-Cauchy:
$$
\det(S^{-1} (A - \lambda I) S) = 
\det(S^{-1}) \det(A - \lambda I) \det(S) = \det(A - \lambda I) 
$$
in quanto $S^{-1}$ e $S$ sono costanti moltiplicative, e quindi gli autovalori $\lambda$ di $A$ e $B$ coincidono.
Inoltre:
$$
B - \lambda I = 0 \Rightarrow S^{-1} A S - \lambda I = 0 \Rightarrow S^{-1}(A - \lambda I) S = 0 \Rightarrow A - \lambda I = 0
$$
cioè si ha lo stesso spazio delle soluzioni.

Presa $(\lambda , v)$ \textit{autocoppia} (coppia autovalore-autovettore) per $A$ abbiamo allora:
$$
B(S^{-1} v) = S^{-1} A S (S^{-1} v) = S^{-1} A v = S^{-1} \lambda v = \lambda (S^{-1} v) 
$$
e quindi $S^{-1} v$ è autovettore per $B$ associato a $\lambda$. \qed

\subsubsection{Matrici diagonalizzabili}
Definiamo le matrici diagonalizzabili come matrici simili ad una matrice diagonale, cioè:
\begin{definition}{Matrice diagonalizzabile}
	Data $A \in \mathbb{C}^{n \times n}$, $A$ si dice diagonalizzabile se $\exists S$ invertibile tale che:
	$$
	S^{-1} A S = A_D
	$$
	con $A_D = \mathrm{diag} (\lambda_1, ..., \lambda_n)$ diagonale.
\end{definition}

Osserviamo che se $A$ è diagonalizzabile, la matrice diagonale (sopra, $A_D$) contiene sulla diagonale gli autovalori di $A$.

Vediamo poi che:
$$
S^{-1} A S = A_D \implies AS = S A_D
$$
risultato piuttosto triste, e posto $S = \begin{pmatrix}
	s_1 & ... & s_n
\end{pmatrix}$:
$$
AS = \begin{pmatrix}
	A s_1 & ... & A s_n
\end{pmatrix} = \begin{pmatrix}
	\lambda_1 s_1 & ... & \lambda_n s_n
\end{pmatrix}
$$
da dove notiamo che da $A s_i = \lambda_i s_i$, la matrice $S$ ha per colonne gli autovettori di $A$ (comodo per il calcolo della matrice $S$ quando $A$ è definita in base canonica).

\par\smallskip

Non tutte le matrici quadrate sono diagonalizzabili.
La diagonalizzabilità dipende infatti dalla possibilità di scegliere $n$ autovettori di $A$ linearmente indpendenti, cioè di trovare una base di $\mathbb{C}^n$ di autovalori di $A$.

Da questo deriva:
\begin{theorem}{Diagonalizzabilità di matrici}
	$A \in \mathbb{C}^{n \times n}$ è diagonalizzabile se e solo se:
	$$
		\alpha(\lambda) = \gamma(\lambda), \quad \forall \lambda
	$$
	dove i $\lambda$ sono gli autovalori di $A$.
\end{theorem}

Questo semplicemente significa che una matrice è diagonalizzabile se le molteplicità algebriche e geometriche di tutti gli autovalori coincidono. 

Si ha quindi che, per $A$ diagonalizzabile, con $x \in \mathbb{C}^n$ si ha che $\exists c_1, ..., c_n \in \mathbb{C}$ tali che:
$$
x = \sum_{i = 1}^n c_i v_j
$$
sugli autovettori $v_j$.

L'utilità sta nel fatto che possiamo scegliere il caso particolare dove la base di autovettori è unitaria/ortogonale (unitaria in $\mathbb{C}$ e ortogonale in $\mathbb{R}$).
Da questo deriva:
\begin{theorem}{Teorema spettrale}
	Se la matrice $A$ è unitaria, cioe $A = A^H$, allora:
	\begin{enumerate}
		\item $A$ è sempre diagonalizzabile;
		\item Gli autovalori di $A$ sono reali;
		\item Si può scegliere una base di autovettori unitaria/ortogonale, cioè tale che:
			\[
				< v_i, v_j > = 	
				\begin{cases}
					0, \quad i \neq j \\ 
					1, \quad i = j
				\end{cases}
			\]
			o in modo equivalente si può trovare $V \in \mathbb{C}^{n \times n}$ tale che:
			$$
				V^H A V = \mathrm{diag}(\lambda_1, ..., \lambda_n)
			$$
			e
			$$
			V^H V = V V^H = I
			$$
	\end{enumerate}
\end{theorem}

Da questo teorema vengono le definizioni:
\begin{definition}{Matrice definita positiva/negativa}
	Una matrice hermitiana viene detta definita positiva (definita negativa) quado gli autovalori $\lambda_i$ sono tutti $> 0$ ($< 0$).
\end{definition}

\subsubsection{Proprietà di autovalori e autovettori}
Vediamo come si comportano autovalori e autovettori sottoposti a diverse operazioni fra matrici.

\begin{enumerate}
	\item \textbf{Somma per identità:} data $(\lambda, v)$ autocoppia per $A \in \mathbb{C}^{n \times n}$, $\delta \in \mathbb{C}$, allora $A + \delta I$ ha come autocoppia $\lambda + \delta, v$.
		Questo semplicemente da:
		$$
			(A + \delta I) v = A v + \delta v = \lambda v + \delta v = (\lambda + \delta) v
		$$

	\item \textbf{Somma di potenze:} supponiamo $q(x) = \sum_{i = 0}^d q_i x^i$. Si può allora definire:
		$$
		q(A) = \sum_{i = 0}^d q_i A^i
		$$
		
		Allora con $(\lambda, v)$ autocoppia di $A$, si avrà che $(q(\lambda), v)$ è autocoppia per $q(A)$.

		Notiamo che la proprietà (1) è il caso $q(x) = x + \delta$.

	\item \textbf{Inversa:} data $(\lambda, v)$ autocoppia per $A$, si avrà che $(\lambda^{-1}, v)$ è autocoppia per $A^{-1}$.
		Questo da:
		$$
			A v = \lambda v \implies A^{-1} A v = \lambda A^{-1} v \implies v = \lambda A^{-1} v
		$$
		da cui:
		$$
		\frac{1}{\lambda} v = A^{-1} v
		$$ \qed

	\item \textbf{Autovalori complessi coniugati:} se $A \in \mathbb{R}^{n \times n}$, allora $\lambda \in \mathbb{C}$ è autovalore di $A$ se e solo se anche $\overline{\lambda}$ coniugato è autovalore di $A$.
		Equivalentemente, gli autovalori complessi arrivano sempre in coppie coniugate.
		Questo da:
		$$
		p(\lambda) = 0 = (-1)^n \lambda^n + (-1)^{n - 1} \sigma_1 \lambda^{n - 1} + ... - \sigma_{n - 1} \lambda + \sigma_{n}
		$$
		con $\lambda \in \mathbb{C} \setminus \mathbb{R}$, dovra essere che:
		$$
		p(\lambda) = 0 = p(\lambda_n)
		$$ \qed

\end{enumerate}

Definiamo infine il \textbf{raggio spettrale}, cioè il \textit{massimo modulo} degli autovalori.
\begin{definition}{Raggio spettrale}
	La quantità $\rho(A) = \max_{j = \{1,...,n\}} |\lambda_j|$ è detta raggio spettrale di $A$.
\end{definition}
Vale il teorema:
\begin{theorem}{Limiti e raggio spettrale}
	$$\lim_{x \rightarrow + \infty} A^x = 0 \, \Leftrightarrow \, \rho(A) < 1$$
\end{theorem}

\end{document}
